# 大数据基础概念

大数据是什么？个人理解，大数据就是海量数据，我们一直在生产这些海量数据，但我们并没有利用起来，而大数据就是将这些海量数据收集起来，然后校验、筛选、分析之后，能用来对各类业务做出决策，再结合人工智能和机器学习来做出预测。数据是来自于过去的，而我们要让它服务于现在，并预测未来。

## 理论概念

### 数据仓库

数据仓库系统从各个IT业务系统中手机数据，对数据进行一系列的校验、清晰、转化，然后按“主题”对数据进行重新组织，最后以“维度模型”的方式呈现出来，上层的数据可视化和报表工具会基于这些维度模型进行数据汇总分析和展现。

#### 数据仓库与数据库的区别

||数据库|数据仓库|
:-:|:-:|:-:
用途|支撑业务运作(OLTP)|进行数据分析(OLAP)
建模方式|关系型范式|维度模型
数据源|单一|多个数据源并保留历史版本
层次|单一|多层，下层数据为上层提供支撑

#### 维度
维度是审视数据的角度，比如时间、地点，度量则是基于数据所计算出来的具体值。在SQL中，group by的属性通常就是维度，而聚合函数算出的值就是度量

数仓中存在维度表和事实表，事实表记录事实的数据记录，维度表则是记录维度的属性，可以和事实相关联，维度的基数就是一个维度所能呈现的不重复值的个数，例如把国家作为维度，那这个维度的基数就是200+左右，即这个世界上有200多个国家。将事实表和维度表通过主键和外键相关联，而维度表之间没有关联，就形成了**星形模型**，如果维度表被细分，并且也形成关联，就形成了**雪花模型**。相对来说比较推崇星形模型，雪花化会导致展现数据时的业务逻辑变复杂。

#### 数据仓库结构
![](https://static.oschina.net/uploads/img/201312/31030207_GgVz.png)

1. 源数据层（SRC层）

对应数据湖，从外部采集数据到这一层，表与源数据一致，数据具有**不可变性**，每个导入周期的数据都是不会被更新的，表示这是一次快照。

2. 明细数据层（DWH层）

标准的数据仓库区，从源数据层中将数据校验，清洗，转化，以一种标准格式存储下来，表和源数据层一一对应，但经过了严格和细致的数据筛选。绝大多数ETL会在数据从源数据层进入明细数据层时完成。

3. 汇总数据层（DMT层）

对应数据集市层，包含事实表，维度表，轻度汇总表（常用业务需求汇总）和宽表（将事实表和维度表全表join）。表结构与源数据层有较大差异，按照维度模型对数据进行重新组织，是数仓开发的一项核心内容

4. 应用数据层（APP层）

面向特定应用提供一层专有的数据封装，其数据结构、组织粒度完全以满足前端应用需求为出发点。

### 大数据平台架构

#### Lambda
现有主流成熟架构，将批处理作业和实时流处理作业分离，各自独立运行，资源隔离。

![](https://img-blog.csdnimg.cn/img_convert/8bde83a6e885f41d3bb6877d677534f0.png)

**批处理作业**即周期性的运行ETL job，将数据从各种数据源向数据仓库转换。

**实时流处理作业**即通过日志和消息队列等，源源不断地获取数据，通过实时计算引擎，进行各种聚合操作后进入下游。

#### Kappa
对Lambda架构的一种简化，使用流计算基数来统一批处理和实时处理两种通道。数据都将以追加的方式写入目标位置，而且之前写入的数据也基本没有机会被改动。

![](https://img-blog.csdnimg.cn/img_convert/37d5e4afb6dcb149c3f372062c5f9312.png)

技术选型

消息队列： Kafka/Pulsar

流计算框架：Flink/Spark Streaming/Storm

#### SMACK
SMACK分别代表5种技术：Spark，Mesos，Akka，Cassandra，Kafka。SMACK成功地融合了批处理和实时处理，但它的融合方式与Kappa有很大差别，它充分而巧妙地利用了选型组件的特性，用一种更加自然和平滑的方式统一了批处理和实时处理。

![](https://img-blog.csdnimg.cn/img_convert/2207166a12a0aaace4d94130ffb491bd.png)

SMACK架构使用Akka进行数据采集（Akka可以应对高并发和实时性要求很高的场景，非常适合IoT领域），然后将数据写入Kafka，接着使用Spark Streaming进行实时流处理，处理的结果和原始数据都写入Cassandra。到这里，所有的做法和Kappa架构是一样的。不同于Kappa架构的地方在于，SMACK架构依然保留了批处理能力，它巧妙地利用了Cassandra的多数据中心（Multiple Datacenters）特性将数据透明地冗余到两个Cassandra集群（集群1用来接收流处理结果，集群2用于批处理分析），供Spark（Spark Core或Spark SQL）读写。

SMACK架构之所以可行，关键是利用了相关产品的特性保证了以下重要的三点:
1. 利用Cassandra的多数据中心机制透明地实现数据冗余，为实时处理和批处理配置专门的存储资源，互不影响;
2. 利用Spark-Cassandra连接器的“本地数据感知”能力，在批处理时让Spark尽量读取Cassandra上本地节点的数据，避免数据的网际传输;
3. 利用Mesos的Marathon和Chronos来配合流式作业和批处理作业。

### 专业术语解释

**MapReduce**---Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行计算。Map--映射，Reduce--归纳。当前的软件实现是指定一个*Map*函数，用来把一组键值对映射成一组新的键值对，指定并发的*Reduce*函数，用来保证所有映射的键值对中的每一个共享相同的键组。

**Google文件系统**---一种专有的分布式文件系统。

**BigTable**---一种压缩的、高性能的、高可扩展性的，基于Google文件系统的数据存储系统，用于存储大规模结构化数据，适用于云端计算。

**Hadoop**---Apache Hadoop是一款支持数据密集型分布式应用程序，它支持在商用硬件构建的大型集群上运行，并且假设硬件故障是常见情况，应该由框架自动处理。

**HDFS**---Hadoop分布式文件系统，存储在商用硬件集群上运行的大文件。具有高容错性和高吞吐量的数据访问。采用主从结构模型，一个HDFS集群由一个NameNode和若干个DataNode组成，其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作，DataNode管理存储的数据。

**Hive**---Apache Hive是一个建立在Hadoop架构上的数据仓库。提供数据的精炼，查询和分析。

**HBase**---Apache HBase是一个开源的非关系型分布式数据库（NoSQL），参考BigTable建模，编程实现语言Java，运行于HDFS文件系统上，为Hadoop提供类似于BigTable规模的服务。

**Spark**---Apache Spark是一个开源集群运算框架。编程语言：Java，Scala，Python，R。其中包括：

- *Spark核心和弹性分布式资料集（RDDs）*：提供分布式任务调度和基本IO功能以及一个可以并行操作，有容错机制的资料集合；
- *Spark SQL*：从核心上带出一种名为SchemaRDD（新版本中叫DataFrame）的资料抽象化概念，提供结构化和半结构化资料相关的支持；
- *Spark Streaming*：充分运用核心的快速调度能力来运行流分析；
- *MLlib*：Spark上的分布式机器学习框架；
- *GraphX*：Spark上的分布式图形处理框架。

**YARN**---Hadoop YARN（Yet Another Resource Negotiator，另一种资源调度器），负责资源的管理和调度。

**Flink**---Apache Flink是开源流处理框架，其核心是用Java及Scala编写的分布式流数据流引擎。它以数据并行和管道方式执行任意流数据程序，提供高吞吐量、低延迟以及对事件-时间处理和状态管理的支持。

**Kafka**---Apache Kafka是由Java和Scala编写的开源流处理平台。目标是为处理实时数据提供一个统一、高吞吐量、低延迟的平台，其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”。可通过Kafka Connect连接外部系统（用于数据输入/输出）。

**Storm**---Apache Storm是一个分布式计算框架，它使用用户创建的“管（spouts）”和“螺栓（bolts）”来定义信息源和操作来允许批量，分布式处理流式数据。

**Akka**---Java虚拟机平台上构建高并发、分布式和容错应用的工具包和运行时。它处理并发的方式是基于Actor模型实现。Actor可以认为就是一个容器，用以存储状态、行为、Mailbox以及子Actor和Supervisor策略。Actor之间不直接通信，而是通过Mail来互通。Actor模式中，每个Actor都恰好有一个Mailbox。Mailbox相当于是一个小型队列，Actor从MailBox里逐条处理消息，改变自身状态，由于Actor内部操作是外部不可见所以具有原子性，所以不需要锁机制。

**Cassandra**---Apache Cassandra是一套开源分布式NoSQL数据库系统，集BigTable和Amazon Dynamo的完全分布式架构于一身。使用宽列存储模型，可理解为一个二维的key-value存储，整个数据模型被定义为map<key1, map<key2, value>>。

**Mesos**---Apache Mesos是一个集群管理器，提供了有效的、跨分布式应用的资源隔离和共享，类似于YARN，可用于管理Hadoop，Spark集群。

**Camel**---Apache Camel是一个基于规则路由和中介引擎，提供企业集成模式的Java对象（POJO）的实现，通过应用程序接口（DSL）来配置路由和中介规则。

**Sqooq**---Apache Sqooq是一个开源工具，用于在Hadoop的HDFS和传统关系型数据之间进行数据的导入导出。

**Oozie**---Apache Oozie是用于Hadoop平台的开源工作流调度引擎，进行Hadoop作业的管理和组织。

**Flume**---Apache Flume是一个分布式，可靠和高可用的海量日志采集、聚合和传输系统，用于有效地收集、聚合和将大量日志数据从许多不同地源移动到一个集中的数据存储。

**CDH**---Cloudera’s Distribution Including Apache Hadoop，Cloudera公司提供的，专门为满足企业需求而构建的一站式大数据平台管理解决方案（包含刚才提到的三个项目），原本开源，现在已收费。

**ELK**---分别表示：Elasticsearch, Logstash, Kibana, 它们都是开源软件。是一套简化版轻量级的数据收集分析存储和展示，现在一般用于日志分析。

- *Elasticsearch* 是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。
- *Logstash* 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。
- *Kibana* 可以为 Logstash 和 ElasticSearch 提供的日志分析友好Web界面，可以帮助汇总、分析和搜索重要数据日志。

**Galera**---Mysql/MariaDB的高可用集群解决方案。


